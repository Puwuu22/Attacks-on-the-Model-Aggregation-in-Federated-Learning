{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rANUVwZ5z8G1"
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation]  pandas matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNob57rk0t1z",
    "outputId": "9f326564-c44d-408e-831e-4a6e84cb9190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.13.0 / PyTorch 2.5.1\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import Parameters, Scalar, FitRes, parameters_to_ndarrays\n",
    "from typing import Optional, Union\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xt47Dal628rM"
   },
   "outputs": [],
   "source": [
    "# Cấu hình thiết bị (CUDA hoặc CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QsCL7xCsGtG1",
    "outputId": "7e41b7c9-e272-4683-9368-0c14f5a7ac97"
   },
   "outputs": [],
   "source": [
    "# Đường dẫn đến tập dữ liệu\n",
    "DATA_PATH = r\"..\\data\\SMSSpamCollection\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv(DATA_PATH, sep='\\t', header=None, names=[\"label\", \"text\"])\n",
    "\n",
    "# Chuyển đổi nhãn 'ham' và 'spam' thành 0 và 1\n",
    "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ITYi82SJJ474"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_CLIENTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Poisoning Attack\n",
    "\n",
    "Nếu partition_id là 1, 3 hoặc 5, dữ liệu của client sẽ bị nhiễu (poisoning attack). Chi tiết tấn công như sau: \n",
    "\n",
    "2. **Text Corruption**:\n",
    "   - Thêm từ ngẫu nhiên từ danh sách [\"spam\", \"fake\", \"malicious\", \"attack\"] vào nội dung tin nhắn để làm \"bẩn\" dữ liệu văn bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QRBk5GL050eJ"
   },
   "outputs": [],
   "source": [
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vectorizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_vector = self.vectorizer.transform([self.texts[idx]]).toarray().squeeze()\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(text_vector, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "def add_noise(text):\n",
    "    \"\"\"Thêm nhiễu vào văn bản bằng cách thay thế từ khóa hoặc chỉnh sửa nội dung.\"\"\"\n",
    "    keywords_to_replace = {\"free\": \"offer\", \"win\": \"get\", \"urgent\": \"important\", \"claim\": \"request\"}\n",
    "    words = text.split()\n",
    "    noisy_words = [keywords_to_replace.get(word, word) for word in words]\n",
    "    return \" \".join(noisy_words)\n",
    "\n",
    "def load_datasets(partition_id: int):\n",
    "    print(f\"Loading dataset for partition ID: {partition_id}\")\n",
    "\n",
    "    # Load raw data\n",
    "    data = pd.read_csv(DATA_PATH, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "    data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "    vectorizer.fit(data[\"text\"])\n",
    "\n",
    "    # Shuffle data and reset index\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Split into NUM_CLIENTS partitions\n",
    "    indices = np.arange(len(data))\n",
    "    split_indices = np.array_split(indices, NUM_CLIENTS)\n",
    "    partition_indices = split_indices[partition_id]\n",
    "    partition_data = data.iloc[partition_indices]\n",
    "\n",
    "    # Poisoning attack\n",
    "    if partition_id in [1, 3, 5]:\n",
    "\n",
    "        print(\"Client 1,3,5 is applying poisoning attack.\")\n",
    "\n",
    "        # Poison 90% of the data\n",
    "        num_poisoned = int(0.9 * len(partition_data))  \n",
    "        poisoned_indices = np.random.choice(len(partition_data), num_poisoned, replace=False)\n",
    "\n",
    "        # Adjust poisoned indices based on the partitioning (shuffled indices)\n",
    "        poisoned_indices = partition_indices[poisoned_indices]\n",
    "\n",
    "        # Flip labels \n",
    "        partition_data.loc[poisoned_indices, \"label\"] = partition_data.loc[poisoned_indices, \"label\"].apply(lambda x: 1 - x)\n",
    "\n",
    "       # Add realistic noise to the text\n",
    "        for idx in poisoned_indices:\n",
    "            original_text = partition_data.loc[idx, \"text\"]\n",
    "            partition_data.loc[idx, \"text\"] = add_noise(original_text)\n",
    "\n",
    "    # Train/val split\n",
    "    train_data, val_data = train_test_split(partition_data, test_size=0.1, random_state=42)\n",
    "    train_dataset = SMSDataset(train_data[\"text\"].tolist(), train_data[\"label\"].tolist(), vectorizer)\n",
    "    val_dataset = SMSDataset(val_data[\"text\"].tolist(), val_data[\"label\"].tolist(), vectorizer)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Test set (for client 5, use its own partition data for testing, for others use last partition)\n",
    "    if partition_id in [1, 3, 5]:\n",
    "        test_data = partition_data  # Use the same poisoned data for testing for client 5\n",
    "    else:\n",
    "        test_data = data.iloc[split_indices[-1]]  # Test data from last partition for all other clients\n",
    "\n",
    "    test_dataset = SMSDataset(test_data[\"text\"].tolist(), test_data[\"label\"].tolist(), vectorizer)\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    print(f\"Partition {partition_id}: Train {len(train_data)}, Val {len(val_data)}, Test {len(test_data)}\")\n",
    "    return trainloader, valloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PNYRSIi038ff",
    "outputId": "d95aa7b3-8e34-4402-f860-be436ca9cd4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wLu3Dfan2FHf"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # 2 output classes (ham, spam)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeW-qbqY2HGu",
    "outputId": "a61bc1ad-a38c-481e-923b-aeb21da99839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for partition ID: 0\n",
      "Partition 0: Train 502, Val 56, Test 557\n",
      "Net(\n",
      "  (fc1): Linear(in_features=5000, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Lấy trainloader từ partition đầu tiên\n",
    "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
    "\n",
    "# Số chiều của đầu vào từ vectorizer\n",
    "input_dim = 5000  # (đã được đặt trong load_datasets max_features=5000)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "net = Net(input_dim).to(DEVICE)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PNKDMzWOCpmP"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Train loss {epoch_loss}, Accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sFjVeY7JKeL6"
   },
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P1YXP90-C7HZ"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "al49ggCSC7oK"
   },
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    input_dim = 5000  # (đã được đặt trong load_datasets max_features=5000)\n",
    "\n",
    "    # Khởi tạo mô hình\n",
    "    net = Net(input_dim).to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
    "\n",
    "    return FlowerClient(net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, dict]]) -> dict:\n",
    "    \"\"\"\n",
    "    Compute weighted average for metrics.\n",
    "    \n",
    "    Args:\n",
    "        metrics: List of tuples (num_examples, metrics_dict).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Aggregated metrics with weighted averages.\n",
    "    \"\"\"\n",
    "    # Ensure there are metrics to aggregate\n",
    "    if not metrics:\n",
    "        return {}\n",
    "\n",
    "    # Initialize storage for weighted sums\n",
    "    weighted_sums = {}\n",
    "    total_examples = 0\n",
    "\n",
    "    for num_examples, metric_dict in metrics:\n",
    "        total_examples += num_examples\n",
    "        for key, value in metric_dict.items():\n",
    "            if key not in weighted_sums:\n",
    "                weighted_sums[key] = 0\n",
    "            weighted_sums[key] += num_examples * value\n",
    "\n",
    "    # Compute weighted averages\n",
    "    aggregated_metrics = {\n",
    "        key: weighted_sums[key] / total_examples for key in weighted_sums\n",
    "    }\n",
    "    return aggregated_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SaveModelStrategy implementation\n",
    "class SaveModelStrategy(FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[ClientProxy, FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "\n",
    "        # Call aggregate_fit from the base class (FedAvg)\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays = parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "            # Save aggregated weights for each round\n",
    "            print(f\"Saving round {server_round} aggregated weights...\")\n",
    "            np.savez(f\"round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
    "\n",
    "            # Save the final model at the end of training\n",
    "            if server_round == 5:\n",
    "                with open(\"DPA_model.pkl\", \"wb\") as f:\n",
    "                    pickle.dump(aggregated_ndarrays, f)\n",
    "                print(\"Final model saved as 'DPA_model.pkl'\")\n",
    "                # Lưu dưới dạng PyTorch\n",
    "                torch.save(aggregated_ndarrays, \"DPA_model.pth\")\n",
    "                print(\"Final model saved as 'DPA_model.pth'\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eadAnMzoDEk8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the server function\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Use the custom SaveModelStrategy\n",
    "    strategy = SaveModelStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=10,\n",
    "        min_evaluate_clients=5,\n",
    "        min_available_clients=10,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    )\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=5)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create a new server instance with the SaveModelStrategy\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3tzMj2s_DJRz"
   },
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Disable oneDNN custom operations to avoid floating-point round-off errors\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Import TensorFlow and other required libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "offZbgFTDHis",
    "outputId": "a93523eb-ae4e-4594-f64e-6cc100855411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-01 11:13:15,330\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:15,332\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:15,332\u001b[0m:     Pre-registering run with id 7625326181220526061\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:15,333\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:15,333\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2024-12-01 11:13:15,334\u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:15,336\u001b[0m:     Buffer time delay: 5s\n",
      "\u001b[92mINFO 2024-12-01 11:13:15,337\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:13:15,341\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2024-12-01 11:13:15,342\u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:20,344\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:20,345\u001b[0m:     Registered 10 nodes\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:20,345\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:20,347\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:20,359\u001b[0m:     Backend config: {'client_resources': {'num_cpus': 1, 'num_gpus': 0.0}, 'init_args': {}, 'actor': {'tensorflow': 0}}\n",
      "2024-12-01 11:13:24,676\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:28,808\u001b[0m:     Constructed ActorPool with: 12 actors\n",
      "\u001b[94mDEBUG 2024-12-01 11:13:28,808\u001b[0m:     Using InMemoryState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Loading dataset for partition ID: 1\n",
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Client 1,3,5 is applying poisoning attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:13:53,306\u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO 2024-12-01 11:13:53,308\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2024-12-01 11:13:53,308\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2024-12-01 11:13:53,309\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:13:53,309\u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO 2024-12-01 11:13:53,310\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Partition 1: Train 502, Val 56, Test 558\n",
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Loading dataset for partition ID: 3\n",
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Client 1,3,5 is applying poisoning attack.\n",
      "\u001b[36m(ClientAppActor pid=20136)\u001b[0m Partition 3: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=28884)\u001b[0m Loading dataset for partition ID: 7\n",
      "\u001b[36m(ClientAppActor pid=12304)\u001b[0m Loading dataset for partition ID: 0\n",
      "\u001b[36m(ClientAppActor pid=28884)\u001b[0m Partition 7: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=18816)\u001b[0m Client 1,3,5 is applying poisoning attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:10,280\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:10,326\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated weights...\n",
      "\u001b[36m(ClientAppActor pid=24768)\u001b[0m Loading dataset for partition ID: 6\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=24768)\u001b[0m Partition 6: Train 501, Val 56, Test 557\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=1052)\u001b[0m Client 1,3,5 is applying poisoning attack.\n",
      "\u001b[36m(ClientAppActor pid=28884)\u001b[0m Client 1,3,5 is applying poisoning attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:10,838\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:10,839\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:14:10,839\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2024-12-01 11:14:10,839\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=28884)\u001b[0m Client 1,3,5 is applying poisoning attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:13,660\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:13,694\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:14,176\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:14,176\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:14:14,177\u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO 2024-12-01 11:14:14,177\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-01 11:14:17,370\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:17,399\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated weights...\n",
      "\u001b[36m(ClientAppActor pid=1052)\u001b[0m Loading dataset for partition ID: 2\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=24024)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=1052)\u001b[0m Client 1,3,5 is applying poisoning attack.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:17,849\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:17,851\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:14:17,852\u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO 2024-12-01 11:14:17,852\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-01 11:14:20,736\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:20,772\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:21,366\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:21,367\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:14:21,367\u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO 2024-12-01 11:14:21,367\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-01 11:14:23,912\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,020\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated weights...\n",
      "Final model saved as 'DPA_model.pkl'\n",
      "Final model saved as 'DPA_model.pth'\n",
      "\u001b[36m(ClientAppActor pid=33752)\u001b[0m Loading dataset for partition ID: 1\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=33752)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=33752)\u001b[0m Client 1,3,5 is applying poisoning attack.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 11:14:24,653\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,658\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 11:14:24,659\u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,659\u001b[0m:      Run finished 5 round(s) in 31.35s\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,661\u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,662\u001b[0m:      \t\tround 1: 0.6287896305322647\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,662\u001b[0m:      \t\tround 2: 0.6946644857525826\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,664\u001b[0m:      \t\tround 3: 0.5380954176187516\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,665\u001b[0m:      \t\tround 4: 0.777078415453434\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,665\u001b[0m:      \t\tround 5: 0.9981233939528465\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,666\u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,666\u001b[0m:      \t{'accuracy': [(1, 0.7285714285714284),\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,667\u001b[0m:      \t              (2, 0.5857142857142857),\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,668\u001b[0m:      \t              (3, 0.7464285714285714),\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,669\u001b[0m:      \t              (4, 0.5857142857142857),\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,670\u001b[0m:      \t              (5, 0.4821428571428571)]}\n",
      "\u001b[92mINFO 2024-12-01 11:14:24,671\u001b[0m:      \n",
      "\u001b[94mDEBUG 2024-12-01 11:14:24,679\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-01 11:14:24,680\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-01 11:14:24,681\u001b[0m:     Triggered stop event for Simulation Engine.\n",
      "\u001b[94mDEBUG 2024-12-01 11:14:25,675\u001b[0m:     Terminated 12 actors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25532)\u001b[0m Loading dataset for partition ID: 8\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=1052)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=1052)\u001b[0m Client 1,3,5 is applying poisoning attack.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-01 11:14:26,670\u001b[0m:     Terminated RayBackend\n",
      "\u001b[94mDEBUG 2024-12-01 11:14:26,672\u001b[0m:     Stopping Simulation Engine now.\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "history = run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    "    verbose_logging=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input SMS:  Win a free iPhone today! Claim your reward now!\n",
      "Prediction: Spam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24504\\180352744.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  final_model_weights = torch.load(\"DPA_model.pth\")\n"
     ]
    }
   ],
   "source": [
    "def predict_sms_with_final_model(sms_text: str):\n",
    "    \"\"\"Predicts whether an SMS is spam or ham using the final trained model.\"\"\"\n",
    "\n",
    "    # Load the final model weights\n",
    "    final_model_weights = torch.load(\"DPA_model.pth\")\n",
    "\n",
    "    # Initialize the model\n",
    "    final_model = Net(input_dim).to(DEVICE)\n",
    "\n",
    "    # Set the model parameters\n",
    "    set_parameters(final_model, final_model_weights)\n",
    "\n",
    "    # Vectorize the input SMS using the same vectorizer used during training\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "    vectorizer.fit(data[\"text\"])  # Fit the vectorizer on the entire dataset\n",
    "    sms_vector = vectorizer.transform([sms_text]).toarray().squeeze()\n",
    "    sms_tensor = torch.tensor(sms_vector, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    with torch.no_grad():\n",
    "        final_model.eval()  # Set the model to evaluation mode\n",
    "        output = final_model(sms_tensor)\n",
    "        _, predicted = torch.max(output.data, 0)  # Get the class with highest probability\n",
    "\n",
    "    # Return the prediction (0 for ham, 1 for spam)\n",
    "    return predicted.item()\n",
    "\n",
    "# Example usage\n",
    "input_sms = input(\"Enter an SMS message: \")\n",
    "prediction = predict_sms_with_final_model(input_sms)\n",
    "\n",
    "print(\"Input SMS: \", input_sms)\n",
    "if prediction == 0:\n",
    "    print(\"Prediction: Ham\")\n",
    "else:\n",
    "    print(\"Prediction: Spam\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spam_email_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
