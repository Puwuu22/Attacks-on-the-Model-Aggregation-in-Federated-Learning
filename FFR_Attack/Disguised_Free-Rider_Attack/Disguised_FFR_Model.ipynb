{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rANUVwZ5z8G1"
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation]  pandas matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNob57rk0t1z",
    "outputId": "9f326564-c44d-408e-831e-4a6e84cb9190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.13.0 / PyTorch 2.5.1\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import Parameters, Scalar, FitRes, parameters_to_ndarrays\n",
    "from typing import Optional, Union\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Xt47Dal628rM"
   },
   "outputs": [],
   "source": [
    "# Cấu hình thiết bị (CUDA hoặc CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_CLIENTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QsCL7xCsGtG1",
    "outputId": "7e41b7c9-e272-4683-9368-0c14f5a7ac97"
   },
   "outputs": [],
   "source": [
    "# Đường dẫn đến tập dữ liệu\n",
    "DATA_PATH = r\"..\\..\\data\\SMSSpamCollection\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv(DATA_PATH, sep='\\t', header=None, names=[\"label\", \"text\"])\n",
    "\n",
    "# Chuyển đổi nhãn 'ham' và 'spam' thành 0 và 1\n",
    "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 5572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = data.shape[0]\n",
    "print(f\"Number of rows in the dataset: {num_rows}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "QRBk5GL050eJ"
   },
   "outputs": [],
   "source": [
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vectorizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_vector = self.vectorizer.transform([self.texts[idx]]).toarray().squeeze()\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(text_vector, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def load_datasets(partition_id: int):\n",
    "    print(f\"Loading dataset for partition ID: {partition_id}\")\n",
    "\n",
    "    # Load raw data\n",
    "    data = pd.read_csv(DATA_PATH, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "    data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "    vectorizer.fit(data[\"text\"])\n",
    "\n",
    "    # Split into NUM_CLIENTS partitions\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    split_indices = np.array_split(indices, NUM_CLIENTS)\n",
    "\n",
    "    # Select partition\n",
    "    partition_indices = split_indices[partition_id]\n",
    "    partition_data = data.iloc[partition_indices]\n",
    "\n",
    "    # Train/val split\n",
    "    train_data, val_data = train_test_split(partition_data, test_size=0.1, random_state=42)\n",
    "    train_dataset = SMSDataset(train_data[\"text\"].tolist(), train_data[\"label\"].tolist(), vectorizer)\n",
    "    val_dataset = SMSDataset(val_data[\"text\"].tolist(), val_data[\"label\"].tolist(), vectorizer)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Test set\n",
    "    test_data = data.iloc[split_indices[-1]]\n",
    "    test_dataset = SMSDataset(test_data[\"text\"].tolist(), test_data[\"label\"].tolist(), vectorizer)\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    print(f\"Partition {partition_id}: Train {len(train_data)}, Val {len(val_data)}, Test {len(test_data)}\")\n",
    "    return trainloader, valloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wLu3Dfan2FHf"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # 2 output classes (ham, spam)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PNKDMzWOCpmP"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Train loss {epoch_loss}, Accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for partition ID: 0\n",
      "Partition 0: Train 502, Val 56, Test 557\n",
      "Net(\n",
      "  (fc1): Linear(in_features=5000, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Lấy trainloader từ partition đầu tiên\n",
    "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
    "\n",
    "# Số chiều của đầu vào từ vectorizer\n",
    "input_dim = 5000  # (đã được đặt trong load_datasets max_features=5000)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "net = Net(input_dim).to(DEVICE)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "sFjVeY7JKeL6"
   },
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "P1YXP90-C7HZ"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, is_bad_client=False):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.is_bad_client = is_bad_client  # Flag to indicate bad client behavior\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        if self.is_bad_client:\n",
    "            # Disguised free-rider attack: Mimic realistic parameters\n",
    "            print(f\"Client behaving badly (disguised): generating fake but plausible parameters.\")\n",
    "            \n",
    "            # Fake \"training\" to modify parameters slightly\n",
    "            fake_parameters = [\n",
    "                param + np.random.normal(0, 0.01, size=param.shape).astype(np.float32)\n",
    "                for param in parameters\n",
    "            ]\n",
    "            \n",
    "            # Mimic normal training statistics\n",
    "            return fake_parameters, len(self.trainloader), {\"loss\": np.random.uniform(0.1, 0.5)}\n",
    "\n",
    "        else:\n",
    "            # Normal client behavior: Perform local training\n",
    "            set_parameters(self.net, parameters)\n",
    "            train(self.net, self.trainloader, epochs=1)\n",
    "            return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Normal evaluation logic\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "al49ggCSC7oK"
   },
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    input_dim = 5000  # Đã được đặt trong load_datasets max_features=5000\n",
    "    net = Net(input_dim).to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
    "\n",
    "    # Xác định bad clients\n",
    "    bad_clients = [2, 5, 8, 9]  # Chọn client 2 và 5 là bad clients\n",
    "    is_bad_client = partition_id in bad_clients\n",
    "\n",
    "    return FlowerClient(net, trainloader, valloader, is_bad_client=is_bad_client).to_client()\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, dict]]) -> dict:\n",
    "    # Ensure there are metrics to aggregate\n",
    "    if not metrics:\n",
    "        return {}\n",
    "\n",
    "    # Initialize storage for weighted sums\n",
    "    weighted_sums = {}\n",
    "    total_examples = 0\n",
    "\n",
    "    for num_examples, metric_dict in metrics:\n",
    "        total_examples += num_examples\n",
    "        for key, value in metric_dict.items():\n",
    "            if key not in weighted_sums:\n",
    "                weighted_sums[key] = 0\n",
    "            weighted_sums[key] += num_examples * value\n",
    "\n",
    "    # Compute weighted averages\n",
    "    aggregated_metrics = {\n",
    "        key: weighted_sums[key] / total_examples for key in weighted_sums\n",
    "    }\n",
    "    return aggregated_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SaveModelStrategy implementation\n",
    "class SaveModelStrategy(FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[ClientProxy, FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "\n",
    "        # Call aggregate_fit from the base class (FedAvg)\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays = parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "            # Save aggregated weights for each round\n",
    "            print(f\"Saving round {server_round} aggregated weights...\")\n",
    "            np.savez(f\"round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
    "\n",
    "            # Save the final model at the end of training\n",
    "            if server_round == 5:\n",
    "                with open(\"Disguised_FFA_model.pkl\", \"wb\") as f:\n",
    "                    pickle.dump(aggregated_ndarrays, f)\n",
    "                print(\"Final model saved as 'Disguised_FFA_model.pkl'\")\n",
    "                # Lưu dưới dạng PyTorch\n",
    "                torch.save(aggregated_ndarrays, \"Disguised_FFA_model.pth\")\n",
    "                print(\"Final model saved as 'Disguised_FFA_model.pth'\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "eadAnMzoDEk8"
   },
   "outputs": [],
   "source": [
    "# Define the server function\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Use the custom SaveModelStrategy\n",
    "    strategy = SaveModelStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=10,\n",
    "        min_evaluate_clients=5,\n",
    "        min_available_clients=10,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    )\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=5)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create a new server instance with the SaveModelStrategy\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3tzMj2s_DJRz"
   },
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Disable oneDNN custom operations to avoid floating-point round-off errors\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Import TensorFlow and other required libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "offZbgFTDHis",
    "outputId": "a93523eb-ae4e-4594-f64e-6cc100855411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-01 12:07:10,949\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:10,979\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:11,200\u001b[0m:     Pre-registering run with id 14917660713302568338\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:11,201\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:11,202\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2024-12-01 12:07:11,203\u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:11,204\u001b[0m:     Buffer time delay: 5s\n",
      "\u001b[92mINFO 2024-12-01 12:07:11,204\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:07:11,206\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2024-12-01 12:07:11,206\u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:16,212\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:16,213\u001b[0m:     Registered 10 nodes\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:16,213\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:16,215\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:16,215\u001b[0m:     Backend config: {'client_resources': {'num_cpus': 1, 'num_gpus': 0.0}, 'init_args': {}, 'actor': {'tensorflow': 0}}\n",
      "2024-12-01 12:07:19,826\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:22,977\u001b[0m:     Constructed ActorPool with: 12 actors\n",
      "\u001b[94mDEBUG 2024-12-01 12:07:22,978\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2024-12-01 12:07:43,295\u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO 2024-12-01 12:07:43,295\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2024-12-01 12:07:43,296\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2024-12-01 12:07:43,297\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:07:43,297\u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO 2024-12-01 12:07:43,298\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=32388)\u001b[0m Loading dataset for partition ID: 3\n",
      "\u001b[36m(ClientAppActor pid=32388)\u001b[0m Partition 3: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=32388)\u001b[0m Loading dataset for partition ID: 0\n",
      "\u001b[36m(ClientAppActor pid=32388)\u001b[0m Partition 0: Train 502, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=22688)\u001b[0m Loading dataset for partition ID: 4\n",
      "\u001b[36m(ClientAppActor pid=20260)\u001b[0m Loading dataset for partition ID: 2\n",
      "\u001b[36m(ClientAppActor pid=22688)\u001b[0m Partition 4: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=20260)\u001b[0m Client behaving badly (disguised): generating fake but plausible parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:07:56,154\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:07:56,181\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:07:56,570\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:07:56,571\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:07:56,572\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2024-12-01 12:07:56,572\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=22688)\u001b[0m Loading dataset for partition ID: 3\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=22688)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=12644)\u001b[0m Client behaving badly (disguised): generating fake but plausible parameters.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:00,319\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:00,353\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:00,732\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:00,739\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:08:00,740\u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO 2024-12-01 12:08:00,741\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-01 12:08:02,493\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:02,529\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:02,909\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:02,911\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:08:02,911\u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO 2024-12-01 12:08:02,912\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=32240)\u001b[0m Loading dataset for partition ID: 3\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20260)\u001b[0m Partition 2: Train 501, Val 56, Test 557\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20260)\u001b[0m Client behaving badly (disguised): generating fake but plausible parameters.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:06,208\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:06,245\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:06,634\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:06,635\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:08:06,636\u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO 2024-12-01 12:08:06,637\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,333\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,385\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated weights...\n",
      "Final model saved as 'Disguised_FFA_model.pkl'\n",
      "Final model saved as 'Disguised_FFA_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-01 12:08:08,765\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,768\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-01 12:08:08,768\u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,769\u001b[0m:      Run finished 5 round(s) in 25.47s\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,769\u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,770\u001b[0m:      \t\tround 1: 0.6713069587945938\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,770\u001b[0m:      \t\tround 2: 0.5043431490659713\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,772\u001b[0m:      \t\tround 3: 0.330770006030798\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,772\u001b[0m:      \t\tround 4: 0.24720262810587884\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,772\u001b[0m:      \t\tround 5: 0.21262860633432865\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,773\u001b[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,773\u001b[0m:      \t{'loss': [(1, 0.14211362792153506),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,774\u001b[0m:      \t          (2, 0.14211362792153506),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,774\u001b[0m:      \t          (3, 0.14211362792153506),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,776\u001b[0m:      \t          (4, 0.14211362792153506),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,776\u001b[0m:      \t          (5, 0.14211362792153506)]}\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,776\u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,778\u001b[0m:      \t{'accuracy': [(1, 0.925),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,778\u001b[0m:      \t              (2, 0.8892857142857142),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,779\u001b[0m:      \t              (3, 0.8821428571428571),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,779\u001b[0m:      \t              (4, 0.9035714285714287),\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,779\u001b[0m:      \t              (5, 0.9035714285714285)]}\n",
      "\u001b[92mINFO 2024-12-01 12:08:08,780\u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=12644)\u001b[0m Loading dataset for partition ID: 0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=11404)\u001b[0m Partition 8: Train 501, Val 56, Test 557\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=11404)\u001b[0m Client behaving badly (disguised): generating fake but plausible parameters.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-01 12:08:08,783\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-01 12:08:08,784\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-01 12:08:08,784\u001b[0m:     Triggered stop event for Simulation Engine.\n",
      "\u001b[94mDEBUG 2024-12-01 12:08:09,728\u001b[0m:     Terminated 12 actors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=12656)\u001b[0m Loading dataset for partition ID: 4\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=12656)\u001b[0m Partition 4: Train 501, Val 56, Test 557\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-01 12:08:10,440\u001b[0m:     Terminated RayBackend\n",
      "\u001b[94mDEBUG 2024-12-01 12:08:10,441\u001b[0m:     Stopping Simulation Engine now.\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "history = run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    "    verbose_logging=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spam_email_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
