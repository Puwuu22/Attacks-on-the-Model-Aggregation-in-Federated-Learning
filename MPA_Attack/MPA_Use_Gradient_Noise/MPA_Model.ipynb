{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rANUVwZ5z8G1"
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation]  pandas matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNob57rk0t1z",
    "outputId": "9f326564-c44d-408e-831e-4a6e84cb9190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.13.0 / PyTorch 2.5.1\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import Parameters, Scalar, FitRes, parameters_to_ndarrays\n",
    "from typing import Optional, Union\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xt47Dal628rM"
   },
   "outputs": [],
   "source": [
    "# Cấu hình thiết bị (CUDA hoặc CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_CLIENTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QsCL7xCsGtG1",
    "outputId": "7e41b7c9-e272-4683-9368-0c14f5a7ac97"
   },
   "outputs": [],
   "source": [
    "# Đường dẫn đến tập dữ liệu\n",
    "DATA_PATH = r\"..\\..\\data\\SMSSpamCollection\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv(DATA_PATH, sep='\\t', header=None, names=[\"label\", \"text\"])\n",
    "\n",
    "# Chuyển đổi nhãn 'ham' và 'spam' thành 0 và 1\n",
    "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QRBk5GL050eJ"
   },
   "outputs": [],
   "source": [
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vectorizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_vector = self.vectorizer.transform([self.texts[idx]]).toarray().squeeze()\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(text_vector, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def load_datasets(partition_id: int):\n",
    "    print(f\"Loading dataset for partition ID: {partition_id}\")\n",
    "\n",
    "    # Load raw data\n",
    "    data = pd.read_csv(DATA_PATH, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "    data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "    vectorizer.fit(data[\"text\"])\n",
    "\n",
    "    # Split into NUM_CLIENTS partitions\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    split_indices = np.array_split(indices, NUM_CLIENTS)\n",
    "\n",
    "    # Select partition\n",
    "    partition_indices = split_indices[partition_id]\n",
    "    partition_data = data.iloc[partition_indices]\n",
    "\n",
    "    # Train/val split\n",
    "    train_data, val_data = train_test_split(partition_data, test_size=0.1, random_state=42)\n",
    "    train_dataset = SMSDataset(train_data[\"text\"].tolist(), train_data[\"label\"].tolist(), vectorizer)\n",
    "    val_dataset = SMSDataset(val_data[\"text\"].tolist(), val_data[\"label\"].tolist(), vectorizer)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Test set\n",
    "    test_data = data.iloc[split_indices[-1]]\n",
    "    test_dataset = SMSDataset(test_data[\"text\"].tolist(), test_data[\"label\"].tolist(), vectorizer)\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    print(f\"Partition {partition_id}: Train {len(train_data)}, Val {len(val_data)}, Test {len(test_data)}\")\n",
    "    return trainloader, valloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PNYRSIi038ff",
    "outputId": "d95aa7b3-8e34-4402-f860-be436ca9cd4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wLu3Dfan2FHf"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # 2 output classes (ham, spam)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeW-qbqY2HGu",
    "outputId": "a61bc1ad-a38c-481e-923b-aeb21da99839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for partition ID: 0\n",
      "Partition 0: Train 502, Val 56, Test 557\n",
      "Net(\n",
      "  (fc1): Linear(in_features=5000, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Lấy trainloader từ partition đầu tiên\n",
    "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
    "\n",
    "# Số chiều của đầu vào từ vectorizer\n",
    "input_dim = 5000  # (đã được đặt trong load_datasets max_features=5000)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "net = Net(input_dim).to(DEVICE)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PNKDMzWOCpmP"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Train loss {epoch_loss}, Accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiến thuật 2: Gradient Poisoning\n",
    "\n",
    "### Mô tả chiến thuật:\n",
    "- Chỉnh sửa gradient trước khi gửi về server nhằm gây ảnh hưởng lớn đến quá trình tổng hợp.\n",
    "\n",
    "### Mục tiêu:\n",
    "Hướng mô hình toàn cục theo một cách sai lệch.\n",
    "Làm giảm hoặc đảo ngược hiệu suất của mô hình toàn cục.\n",
    "\n",
    "### Chiến thuật cụ thể:\n",
    "Gradient Scaling (Phóng đại hoặc giảm gradient):\n",
    "\n",
    "Mục tiêu: Tăng ảnh hưởng của client độc hại hoặc làm gradient của client độc hại mất trọng số.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sFjVeY7JKeL6"
   },
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "P1YXP90-C7HZ"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, is_bad_client=False, scale_factor=10):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.is_bad_client = is_bad_client\n",
    "        self.scale_factor = scale_factor  # Hệ số để chỉnh sửa gradient\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        # Lấy tham số của mô hình\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Cập nhật tham số từ mô hình toàn cục\n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "        # Huấn luyện mô hình cục bộ\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "\n",
    "        # Lấy gradient (delta tham số) sau khi huấn luyện\n",
    "        original_parameters = get_parameters(self.net)\n",
    "        gradient = [\n",
    "            original - updated\n",
    "            for original, updated in zip(parameters, original_parameters)\n",
    "        ]\n",
    "\n",
    "        # Gradient Poisoning\n",
    "        if self.is_bad_client:\n",
    "            print(f\"Client behaving badly (gradient poisoning): scaling gradients.\")\n",
    "            poisoned_gradient = [g * self.scale_factor for g in gradient]\n",
    "        else:\n",
    "            poisoned_gradient = gradient\n",
    "\n",
    "        # Cập nhật tham số bị tấn công\n",
    "        poisoned_parameters = [\n",
    "            updated - g for updated, g in zip(original_parameters, poisoned_gradient)\n",
    "        ]\n",
    "        return poisoned_parameters, len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Đánh giá mô hình trên tập kiểm tra\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "al49ggCSC7oK"
   },
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    input_dim = 5000  # Đã được đặt trong load_datasets max_features=5000\n",
    "    net = Net(input_dim).to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
    "\n",
    "    # Định nghĩa các client độc hại (ví dụ: chỉ định partition ID là bad client)\n",
    "    bad_clients = [1, 3, 5]  # Danh sách các partition ID của client độc hại\n",
    "    is_bad_client = partition_id in bad_clients\n",
    "\n",
    "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
    "\n",
    "    return FlowerClient(net, trainloader, valloader, is_bad_client).to_client()\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, dict]]) -> dict:\n",
    "    # Ensure there are metrics to aggregate\n",
    "    if not metrics:\n",
    "        return {}\n",
    "\n",
    "    # Initialize storage for weighted sums\n",
    "    weighted_sums = {}\n",
    "    total_examples = 0\n",
    "\n",
    "    for num_examples, metric_dict in metrics:\n",
    "        total_examples += num_examples\n",
    "        for key, value in metric_dict.items():\n",
    "            if key not in weighted_sums:\n",
    "                weighted_sums[key] = 0\n",
    "            weighted_sums[key] += num_examples * value\n",
    "\n",
    "    # Compute weighted averages\n",
    "    aggregated_metrics = {\n",
    "        key: weighted_sums[key] / total_examples for key in weighted_sums\n",
    "    }\n",
    "    return aggregated_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SaveModelStrategy implementation\n",
    "class SaveModelStrategy(FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[ClientProxy, FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "\n",
    "        # Call aggregate_fit from the base class (FedAvg)\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays = parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "            # Save aggregated weights for each round\n",
    "            print(f\"Saving round {server_round} aggregated weights...\")\n",
    "            np.savez(f\"round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
    "\n",
    "            # Save the MPA model at the end of training\n",
    "            if server_round == 5:\n",
    "                with open(\"MPA_model.pkl\", \"wb\") as f:\n",
    "                    pickle.dump(aggregated_ndarrays, f)\n",
    "                print(\"MPA model saved as 'MPA_model.pkl'\")\n",
    "                # Lưu dưới dạng PyTorch\n",
    "                torch.save(aggregated_ndarrays, \"MPA_model.pth\")\n",
    "                print(\"MPA model saved as 'MPA_model.pth'\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eadAnMzoDEk8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the server function\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Use the custom SaveModelStrategy\n",
    "    strategy = SaveModelStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=10,\n",
    "        min_evaluate_clients=5,\n",
    "        min_available_clients=10,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    )\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=5)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create a new server instance with the SaveModelStrategy\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3tzMj2s_DJRz"
   },
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Disable oneDNN custom operations to avoid floating-point round-off errors\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Import TensorFlow and other required libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "offZbgFTDHis",
    "outputId": "a93523eb-ae4e-4594-f64e-6cc100855411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-02 01:03:32,376\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:32,378\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:32,380\u001b[0m:     Pre-registering run with id 7088696580099432266\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:32,381\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:32,383\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2024-12-02 01:03:32,410\u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:32,928\u001b[0m:     Buffer time delay: 5s\n",
      "\u001b[92mINFO 2024-12-02 01:03:32,930\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:03:32,934\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2024-12-02 01:03:32,935\u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:37,950\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:37,950\u001b[0m:     Registered 10 nodes\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:37,955\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:37,955\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:37,955\u001b[0m:     Backend config: {'client_resources': {'num_cpus': 1, 'num_gpus': 0.0}, 'init_args': {}, 'actor': {'tensorflow': 0}}\n",
      "2024-12-02 01:03:45,784\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:50,884\u001b[0m:     Constructed ActorPool with: 12 actors\n",
      "\u001b[94mDEBUG 2024-12-02 01:03:50,885\u001b[0m:     Using InMemoryState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Loading dataset for partition ID: 0\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Partition 0: Train 502, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Loading dataset for partition ID: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:04:24,358\u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO 2024-12-02 01:04:24,358\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2024-12-02 01:04:24,364\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2024-12-02 01:04:24,366\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:04:24,368\u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO 2024-12-02 01:04:24,369\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Partition 0: Train 502, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Loading dataset for partition ID: 0\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Partition 0: Train 502, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Loading dataset for partition ID: 0\n",
      "\u001b[36m(ClientAppActor pid=36500)\u001b[0m Partition 0: Train 502, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Loading dataset for partition ID: 9\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Partition 9: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Loading dataset for partition ID: 9\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Partition 9: Train 501, Val 56, Test 557\n",
      "\u001b[36m(ClientAppActor pid=33984)\u001b[0m Client behaving badly (gradient poisoning): scaling gradients.\n",
      "\u001b[36m(ClientAppActor pid=13408)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 16x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13408)\u001b[0m Loading dataset for partition ID: 3\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:04:48,796\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:49,093\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:04:49,984\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:49,986\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:04:49,987\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2024-12-02 01:04:49,989\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-02 01:04:53,514\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:53,571\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated weights...\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Client behaving badly (gradient poisoning): scaling gradients.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2112)\u001b[0m Partition 3: Train 501, Val 56, Test 557\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7096)\u001b[0m Loading dataset for partition ID: 5\u001b[32m [repeated 31x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:04:54,540\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:54,542\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:04:54,543\u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO 2024-12-02 01:04:54,545\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-02 01:04:58,203\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:58,256\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated weights...\n",
      "\u001b[36m(ClientAppActor pid=2092)\u001b[0m Client behaving badly (gradient poisoning): scaling gradients.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20796)\u001b[0m Partition 8: Train 501, Val 56, Test 557\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=20796)\u001b[0m Loading dataset for partition ID: 8\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:04:59,245\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:04:59,248\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:04:59,249\u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO 2024-12-02 01:04:59,250\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO 2024-12-02 01:05:02,991\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:05:03,062\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:05:04,249\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:05:04,249\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:05:04,249\u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO 2024-12-02 01:05:04,256\u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=31784)\u001b[0m Client behaving badly (gradient poisoning): scaling gradients.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14712)\u001b[0m Partition 0: Train 502, Val 56, Test 557\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=11592)\u001b[0m Loading dataset for partition ID: 6\u001b[32m [repeated 31x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:05:07,729\u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:05:07,898\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated weights...\n",
      "MPA model saved as 'MPA_model.pkl'\n",
      "MPA model saved as 'MPA_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2024-12-02 01:05:08,949\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,952\u001b[0m:      \n",
      "\u001b[92mINFO 2024-12-02 01:05:08,953\u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,955\u001b[0m:      Run finished 5 round(s) in 44.58s\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,963\u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,967\u001b[0m:      \t\tround 1: 1.1667768165469168\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,968\u001b[0m:      \t\tround 2: 0.46377829015254973\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,969\u001b[0m:      \t\tround 3: 1.279293768852949\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,970\u001b[0m:      \t\tround 4: 0.2269435554742813\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,971\u001b[0m:      \t\tround 5: 1.0610921427607536\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,972\u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,973\u001b[0m:      \t{'accuracy': [(1, 0.9107142857142858),\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,973\u001b[0m:      \t              (2, 0.8785714285714287),\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,975\u001b[0m:      \t              (3, 0.8892857142857142),\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,976\u001b[0m:      \t              (4, 0.8642857142857144),\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,977\u001b[0m:      \t              (5, 0.9035714285714285)]}\n",
      "\u001b[92mINFO 2024-12-02 01:05:08,978\u001b[0m:      \n",
      "\u001b[94mDEBUG 2024-12-02 01:05:08,994\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-02 01:05:08,997\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2024-12-02 01:05:08,999\u001b[0m:     Triggered stop event for Simulation Engine.\n",
      "\u001b[94mDEBUG 2024-12-02 01:05:09,892\u001b[0m:     Terminated 12 actors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13408)\u001b[0m Client behaving badly (gradient poisoning): scaling gradients.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2092)\u001b[0m Partition 4: Train 501, Val 56, Test 557\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2092)\u001b[0m Loading dataset for partition ID: 4\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-12-02 01:05:11,258\u001b[0m:     Terminated RayBackend\n",
      "\u001b[94mDEBUG 2024-12-02 01:05:11,270\u001b[0m:     Stopping Simulation Engine now.\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "history = run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    "    verbose_logging=True\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spam_email_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
